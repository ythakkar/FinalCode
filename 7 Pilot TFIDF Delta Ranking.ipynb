{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy.spatial.distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qa = np.genfromtxt(\"uid_qa.txt\", delimiter = \",\", names = True, dtype = [('int64'), ('int64'), ('int64'), ('U256'), ('U128'),])\n",
    "fe = np.genfromtxt(\"uid_pre_elim.txt\", delimiter = \",\", names = True, dtype = [('int64'), ('int64'), ('int64'), ('U256'), ('U256'),])\n",
    "ftd = np.genfromtxt(\"face_id_descr.txt\", delimiter = \";\", skip_header = 1 , usecols = np.arange(0,2), dtype = [('U16'), ('U2056')])\n",
    "fe.dtype.names = ('uniqueID', 'bn', 'qn', 'pre_que', 'curr_elim')\n",
    "ftd.dtype.names = ('img_id', 'description')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## first convert strings to list of rows equal to rows in fe\n",
    "def mk_list(str_vector):\n",
    "    des_byid = str_vector\n",
    "    all_x = []\n",
    "    for i in des_byid:\n",
    "        j = i.split()\n",
    "        #if len(j) > 0:\n",
    "        all_x.append(j)\n",
    "\n",
    "    return all_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_x = mk_list(fe['pre_que']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##check blanks\n",
    "## As there are some rows where there is only one image or blank/erronous question. We check that and save those indices.\n",
    "## create blank list\n",
    "#good_index = ['True']*len(all_x)\n",
    "\n",
    "bl =[]\n",
    "\n",
    "for img,q in zip(enumerate(all_x), mk_list(qa['que'])):\n",
    "    if (len(img[1]) <2 or len(q) < 2) and img[0] not in bl:\n",
    "        bl.append(img[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Now for each row in the list above, find description and add it\n",
    "all_i_txt1 = []\n",
    "original_ind = []\n",
    "bl_ind = []\n",
    "\n",
    "for rown in range(len(all_x)):\n",
    "    if rown in bl:\n",
    "        bl_ind.append(rown)\n",
    "    else:\n",
    "        #print(all_x.index)\n",
    "        int_i_txt = []\n",
    "        for img in all_x[rown]:\n",
    "            if img in ftd['img_id']:\n",
    "                d = str(ftd['description'][list(ftd['img_id']).index(img)])\n",
    "                int_i_txt.append(str(d))\n",
    "        original_ind.append(rown)\n",
    "        all_i_txt1.append(int_i_txt)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add question and answer to each data point\n",
    "all_i_txt = [row + [qa['que'][rn].strip(), qa['ans'][rn].strip()] for rn, row in zip(original_ind, all_i_txt1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(all_i_txt[0])add function in a py file\n",
    "##basic model\n",
    "tf = TfidfVectorizer(ngram_range = (2,5), sublinear_tf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## all similarities\n",
    "all_sim = []\n",
    "for l in range(len(all_i_txt)):\n",
    "    H = tf.fit_transform(all_i_txt[l])\n",
    "    sim = cosine_similarity(H)\n",
    "    all_sim.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#similarities[-2] meaning taking only the array for question\n",
    "all_sim_q = []\n",
    "for i in range(len(all_sim)):\n",
    "    all_sim_q.append(all_sim[i][-2][:-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Sort all the above similarities with argsort which gives indices\n",
    "## or we should not take top5 and make a threshold above which we will include it in the list of output?\n",
    "sorted_ind = []\n",
    "for si in all_sim_q:\n",
    "    y_top = si.argsort()[::-1]\n",
    "    sorted_ind.append(y_top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## with above indices, create new sorted array per que, this is done to then find max step difference \n",
    "sorted_sim_all = []\n",
    "for q,w in zip(sorted_ind, all_sim_q):\n",
    "    sorted_sim = []\n",
    "    for e in q:\n",
    "        sorted_sim.append(w[e])\n",
    "    sorted_sim_all.append(sorted_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##find the difference between two similarity score in each array.\n",
    "sim_dif_all = []\n",
    "\n",
    "for d in range(len(sorted_sim_all)):\n",
    "    sim_dif = [sorted_sim_all[d][f-1] - sorted_sim_all[d][f] for f in range(1, len(sorted_sim_all[d]))]\n",
    "    sim_dif_all.append(sim_dif)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Find maximum difference in similarity scores per row and also find the indice where to cut-off\n",
    "\n",
    "max_dif = []\n",
    "max_dif_ind =[]\n",
    "for g in range(len(sim_dif_all)):\n",
    "    \n",
    "    maxi= max(sim_dif_all[g])\n",
    "    max_dif.append(maxi)\n",
    "    max_dif_ind.append(sim_dif_all[g].index(maxi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Cut off sorted indices till maximum difference index\n",
    "sorted_ind_lim = [indi[0:max_indi+1] for indi,max_indi in zip(sorted_ind, max_dif_ind)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##clean_all_x Without outliers\n",
    "all_x_clean = [all_x[i] for i in original_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_img = zip(all_x_clean, sorted_ind_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert to img_id from index to match with actual image ids selcted by participant\n",
    "def mk_imgid(arr):\n",
    "    y_pred = []\n",
    "    for i,j in arr:\n",
    "        yp = []\n",
    "        for s in j:\n",
    "            yp.append(i[s])\n",
    "        y_pred.append(yp)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## images predicted to be eliminated\n",
    "pred_img = mk_imgid(top_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cheat1 = mk_list(fe['curr_elim'])\n",
    "all_cheat = [all_cheat1[i] for i in original_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_all= [len(set(a).intersection(set(p)))/len(set(p)) if len(p) > 0 else 0 for a,p in zip(all_cheat, pred_img)]\n",
    "rec_all = [len(set(a).intersection(set(p)))/len(set(a)) if len(a) > 0 else 0 for a,p in zip(all_cheat, pred_img)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs_all= [(0.5*0.5 + 1)*pr*re/ (0.5*0.5*pr + re) if pr > 0 or re >0 else 0 for pr, re in zip(pre_all, rec_all)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_mean = np.mean(np.array(pre_all))\n",
    "rec_mean = np.mean(np.array(rec_all))\n",
    "fs_mean = np.mean(np.array(fs_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op = [\"12\", \"TFIDF\", \"ngram_range 2,6, sublinear_tf true\", \"Cosinesimilarity and ranking difference\",str(pre_mean), str(rec_mean), str(fs_mean)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Results with description.txt', 'a') as f:\n",
    "    f.write('; '.join(op)+ '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
